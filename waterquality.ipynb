{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Tesnor flow \n",
    "#Used Tensorflow to create a neural net and then using the neural net to predict \n",
    "#Whether or not the sample of water is Potable or Non-Potable \n",
    "#%pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "data=pd.read_csv('water_potability.csv')\n",
    "data.head(10)\n",
    "## null value check\n",
    "data.isnull().sum()\n",
    "\n",
    "data.shape\n",
    "100*data.isnull().sum()/len(data)\n",
    "\n",
    "data_dropped = data.dropna()\n",
    "print(\"The total missing value accounts\", 100-round(data_dropped.shape[0]/data.shape[0]*100), \"% of the total data\")\n",
    "#It might not be a good idea to drop all the missing value columns. \n",
    "#Let's continue exploring the dataset and then deal with these missing values.\n",
    "\n",
    "data[data['Potability']==0].describe()\n",
    "data[data['Potability']==0][['ph','Sulfate','Trihalomethanes']].median()\n",
    "#The difference between mean and median values of non-potable water is small.\n",
    "\n",
    "#Let's continue to see the result for potable water\n",
    "data[data['Potability']==1].describe()\n",
    "\n",
    "data[data['Potability']==1][['ph','Sulfate','Trihalomethanes']].median()\n",
    "#The difference between mean and median values of potable water is also small.\n",
    "\n",
    "#We can use the overall median of the feature to impute values.\n",
    "data['ph'].fillna(value=data['ph'].median(), inplace=True)\n",
    "data['Sulfate'].fillna(value=data['Sulfate'].median(), inplace=True)\n",
    "data['Trihalomethanes'].fillna(value=data['Trihalomethanes'].median(), inplace=True)\n",
    "\n",
    "data.info()\n",
    "## null value check\n",
    "data.isnull().sum()\n",
    "data.describe()\n",
    "#Check our target variable 'Potability'\n",
    "100*data['Potability'].value_counts(normalize=True)\n",
    "data.columns\n",
    "len(data[data['Potability']==1]),len(data[data['Potability']==0])\n",
    "correlation = data.corr()\n",
    "print(correlation['Potability'].sort_values(ascending = False),'\\n')\n",
    "\n",
    "trace=go.Histogram(\n",
    "    x= data.Potability,\n",
    "    opacity = 0.75,\n",
    "    name = \"Water Quality\",\n",
    "    marker = dict(color = 'blue'))\n",
    "hist_data=[trace]\n",
    "hist_layout=go.Layout(barmode='overlay',bargap=0.75,\n",
    "            title='Water Quality',\n",
    "            xaxis=dict(title='Not potable & Potable'),\n",
    "            yaxis=dict(title='Frequency'),)\n",
    "fig=go.Figure(data=hist_data,layout=hist_layout)\n",
    "iplot(fig)\n",
    "\n",
    "X=data[data.columns[:-1]].values\n",
    "y=data[data.columns[-1]].values\n",
    "\n",
    "X.shape,y.shape\n",
    "\n",
    "scaler=StandardScaler()\n",
    "X=scaler.fit_transform(X)\n",
    "dp=np.hstack((X,np.reshape(y,(-1,1))))\n",
    "transformed_data=pd.DataFrame(dp,columns=data.columns)\n",
    "X\n",
    "\n",
    "#RANDOM OVER SAMPLER\n",
    "over=RandomOverSampler()\n",
    "X,y =over.fit_resample(X,y)\n",
    "dp=np.hstack((X,np.reshape(y,(-1,1))))\n",
    "transformed_data=pd.DataFrame(dp,columns=data.columns)\n",
    "\n",
    "len(transformed_data[transformed_data[\"Potability\"]==1]),len(transformed_data[transformed_data[\"Potability\"]==0])\n",
    "\n",
    "X_train,X_temp,y_train,y_temp = train_test_split(X,y,test_size=0.4,random_state=0)\n",
    "X_valid,X_test,y_valid,y_test = train_test_split(X_temp,y_temp,test_size=0.5,random_state=0)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "                             tf.keras.layers.Dense(16,activation='relu'), # if x<=0-->0, x>0 -->x\n",
    "                             tf.keras.layers.Dense(16,activation='relu'),\n",
    "                             tf.keras.layers.Dense(1,activation=\"sigmoid\")                       \n",
    "                            ])\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.evaluate(X_train,y_train)\n",
    "model.evaluate(X_valid,y_valid)\n",
    "model.fit(X_train,y_train,batch_size=18,epochs=20, validation_data=(X_valid,y_valid))\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "nn_results=model.evaluate(X_test,y_test)\n",
    "print(\"test loss, test acc:\", nn_results)\n",
    "nn_ac=nn_results[1]\n",
    "\n",
    "#RANDOM FOREST MODEL\n",
    "# Split features and target into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6, random_state = 0,stratify=y)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classificationModel=RandomForestClassifier(n_estimators =100,min_samples_leaf =1, random_state = 0)\n",
    "Y_train=rf_classificationModel.fit(X_train,y_train)\n",
    "#Y_train=rf_classificationModel.fit(X_train,y_train)\n",
    "\n",
    "#Y_train=rf_classificationModel.fit(X_train,y_train)\n",
    "Y_pred = rf_classificationModel.predict(X_test)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RmFor_acc = accuracy_score(y_test, Y_pred)\n",
    "print('Accuracy Score',RmFor_acc)\n",
    "#print('Accuracy Score', metrics.accuracy_score(y_test,Y_pred))\n",
    "\n",
    "# View the classification report for test data and predictions\n",
    "# checking mean_squared error\n",
    "MSE = mean_squared_error(y_test,Y_pred) \n",
    "\n",
    "# checking root mean squared error\n",
    "RMSE = np.sqrt(MSE)\n",
    "print('mean squared error is : ',MSE) \n",
    "print('root mean squared error is : ',RMSE)\n",
    "print(classification_report(y_test, Y_pred))\n",
    "\n",
    "\n",
    "#SVM\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "# create the model\n",
    "SVM = SVC(kernel ='rbf', random_state = 0)\n",
    "# model training\n",
    "SVM.fit(X_train, y_train)\n",
    "# prediction\n",
    "SVM_pred = SVM.predict(X_test)\n",
    "# accuracy\n",
    "SVM_acc = accuracy_score(y_test, SVM_pred)\n",
    "SVM_acc\n",
    "print(\"The accuracy for SVM is\", SVM_acc)\n",
    "print(\"The classification report using SVM is:\", SVM_acc)\n",
    "print(classification_report(y_test, SVM_pred))\n",
    "\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Model':['Neural Network','Random Forest','SVM'],\n",
    "    'Accuracy' :[nn_ac,RmFor_acc,SVM_acc ]\n",
    "})\n",
    "models.sort_values(by='Accuracy', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x='Model', y='Accuracy', data = models, \n",
    "            order = models.sort_values(\"Accuracy\").Model,\n",
    "           palette = 'Blues_d')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d96483902bceab5089ae0a576879027197826963012812f3edea73ef4f5f3e6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
